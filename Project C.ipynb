{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Kevin Wang RJ Lombardi Alex Wan\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      1460.000000\n",
       "mean     180921.195890\n",
       "std       79442.502883\n",
       "min       34900.000000\n",
       "25%      129975.000000\n",
       "50%      163000.000000\n",
       "75%      214000.000000\n",
       "max      755000.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = pd.read_csv(\"train.csv\")\n",
    "target=hp['SalePrice']\n",
    "features=hp[['OverallQual','GrLivArea','1stFlrSF']]\n",
    "target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp3 = hp['OverallQual']\n",
    "hp5 = hp['HouseStyle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp3 = hp3>5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hp3 = hp3*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp['OverallQual'] = hp3\n",
    "#0 = after and including 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "922"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(hp['OverallQual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8841095890410958"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "922/1460*1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.456241032999\n",
      "0.45551549047\n",
      "0.425882352941\n",
      "0.439404774066\n",
      "0.403064481805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "housedata_target=hp['OverallQual']\n",
    "housedata_features=hp[['GarageCars', 'GrLivArea', 'YearBuilt', 'TotalBsmtSF', 'FullBath', 'SalePrice']]\n",
    "#1\n",
    "train_features, valid_features, train_target, valid_target = train_test_split(housedata_features, housedata_target,\n",
    "                                                                              test_size=0.15, random_state=29)\n",
    "logit = LogisticRegression()\n",
    "logit.fit(train_features, train_target)\n",
    "\n",
    "valid_sum = sum(valid_target)\n",
    "pred_logit = logit.predict(train_features)\n",
    "pred_sum = sum(pred_logit)\n",
    "if(valid_sum > len(valid_target)/2):\n",
    "    baseline_acc = valid_sum/len(valid_target)\n",
    "else:\n",
    "    baseline_acc = (len(valid_target)-valid_sum)/len(valid_target)\n",
    "if(pred_sum > len(predictions)/2):\n",
    "    predict_acc = pred_sum/len(pred_logit)\n",
    "else:\n",
    "    predict_acc = (len(predictions)-pred_sum)/len(pred_logit)\n",
    "##if(predict_sum > len(predictions)/2):\n",
    "##    predict_acc = predict_sum/len(predictions)\n",
    "##else:\n",
    "##    predict_acc = (len(predictions)-predict_sum)/len(predictions)\n",
    "\n",
    "\n",
    "predict_acc = accuracy_score(y_true = train_target, y_pred = pred_logit)\n",
    "\n",
    "print((predict_acc-baseline_acc)/baseline_acc)\n",
    "\n",
    "#2\n",
    "train_features, valid_features, train_target, valid_target = train_test_split(housedata_features, housedata_target,\n",
    "                                                                              test_size=0.13, random_state=58)\n",
    "logit = LogisticRegression()\n",
    "logit.fit(train_features, train_target)\n",
    "\n",
    "valid_sum = sum(valid_target)\n",
    "pred_logit = logit.predict(train_features)\n",
    "pred_sum = sum(pred_logit)\n",
    "if(valid_sum > len(valid_target)/2):\n",
    "    baseline_acc = valid_sum/len(valid_target)\n",
    "else:\n",
    "    baseline_acc = (len(valid_target)-valid_sum)/len(valid_target)\n",
    "if(pred_sum > len(predictions)/2):\n",
    "    predict_acc = pred_sum/len(pred_logit)\n",
    "else:\n",
    "    predict_acc = (len(predictions)-pred_sum)/len(pred_logit)\n",
    "##if(predict_sum > len(predictions)/2):\n",
    "##    predict_acc = predict_sum/len(predictions)\n",
    "##else:\n",
    "##    predict_acc = (len(predictions)-predict_sum)/len(predictions)\n",
    "\n",
    "\n",
    "predict_acc = accuracy_score(y_true = train_target, y_pred = pred_logit)\n",
    "\n",
    "print((predict_acc-baseline_acc)/baseline_acc)\n",
    "\n",
    "#3\n",
    "train_features, valid_features, train_target, valid_target = train_test_split(housedata_features, housedata_target,\n",
    "                                                                              test_size=0.15, random_state=1)\n",
    "logit = LogisticRegression()\n",
    "logit.fit(train_features, train_target)\n",
    "\n",
    "valid_sum = sum(valid_target)\n",
    "pred_logit = logit.predict(train_features)\n",
    "pred_sum = sum(pred_logit)\n",
    "if(valid_sum > len(valid_target)/2):\n",
    "    baseline_acc = valid_sum/len(valid_target)\n",
    "else:\n",
    "    baseline_acc = (len(valid_target)-valid_sum)/len(valid_target)\n",
    "if(pred_sum > len(predictions)/2):\n",
    "    predict_acc = pred_sum/len(pred_logit)\n",
    "else:\n",
    "    predict_acc = (len(predictions)-pred_sum)/len(pred_logit)\n",
    "##if(predict_sum > len(predictions)/2):\n",
    "##    predict_acc = predict_sum/len(predictions)\n",
    "##else:\n",
    "##    predict_acc = (len(predictions)-predict_sum)/len(predictions)\n",
    "\n",
    "\n",
    "predict_acc = accuracy_score(y_true = train_target, y_pred = pred_logit)\n",
    "\n",
    "print((predict_acc-baseline_acc)/baseline_acc)\n",
    "\n",
    "#4\n",
    "train_features, valid_features, train_target, valid_target = train_test_split(housedata_features, housedata_target,\n",
    "                                                                              test_size=0.14, random_state=80)\n",
    "logit = LogisticRegression()\n",
    "logit.fit(train_features, train_target)\n",
    "\n",
    "valid_sum = sum(valid_target)\n",
    "pred_logit = logit.predict(train_features)\n",
    "pred_sum = sum(pred_logit)\n",
    "if(valid_sum > len(valid_target)/2):\n",
    "    baseline_acc = valid_sum/len(valid_target)\n",
    "else:\n",
    "    baseline_acc = (len(valid_target)-valid_sum)/len(valid_target)\n",
    "if(pred_sum > len(predictions)/2):\n",
    "    predict_acc = pred_sum/len(pred_logit)\n",
    "else:\n",
    "    predict_acc = (len(predictions)-pred_sum)/len(pred_logit)\n",
    "##if(predict_sum > len(predictions)/2):\n",
    "##    predict_acc = predict_sum/len(predictions)\n",
    "##else:\n",
    "##    predict_acc = (len(predictions)-predict_sum)/len(predictions)\n",
    "\n",
    "\n",
    "predict_acc = accuracy_score(y_true = train_target, y_pred = pred_logit)\n",
    "\n",
    "print((predict_acc-baseline_acc)/baseline_acc)\n",
    "\n",
    "#5\n",
    "train_features, valid_features, train_target, valid_target = train_test_split(housedata_features, housedata_target,\n",
    "                                                                              test_size=0.13, random_state=103)\n",
    "logit = LogisticRegression()\n",
    "logit.fit(train_features, train_target)\n",
    "\n",
    "valid_sum = sum(valid_target)\n",
    "pred_logit = logit.predict(train_features)\n",
    "pred_sum = sum(pred_logit)\n",
    "if(valid_sum > len(valid_target)/2):\n",
    "    baseline_acc = valid_sum/len(valid_target)\n",
    "else:\n",
    "    baseline_acc = (len(valid_target)-valid_sum)/len(valid_target)\n",
    "if(pred_sum > len(predictions)/2):\n",
    "    predict_acc = pred_sum/len(pred_logit)\n",
    "else:\n",
    "    predict_acc = (len(predictions)-pred_sum)/len(pred_logit)\n",
    "##if(predict_sum > len(predictions)/2):\n",
    "##    predict_acc = predict_sum/len(predictions)\n",
    "##else:\n",
    "##    predict_acc = (len(predictions)-predict_sum)/len(predictions)\n",
    "\n",
    "\n",
    "predict_acc = accuracy_score(y_true = train_target, y_pred = pred_logit)\n",
    "\n",
    "print((predict_acc-baseline_acc)/baseline_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80193236715\n",
      "0.848780487805\n",
      "0.841346153846\n",
      "0.793269230769\n",
      "0.767441860465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "# target is stored in y\n",
    "y = hp['HouseStyle']\n",
    "\n",
    "# X contains all other features, which we will use to predict target\n",
    "X = hp.drop('HouseStyle', axis=1)\n",
    "\n",
    "# we use .SVC function to make the classification object\n",
    "model = svm.SVC(kernel='linear', C=1,gamma=1)\n",
    "\n",
    "# split the training and testing data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=20)\n",
    "a = [word[1] for word in Counter(Y_test).most_common(1)]\n",
    "baseline_acc = a[0]/len(Y_test)\n",
    "\n",
    "# fit the model to the training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# predict on the testing data\n",
    "model.predict(X_test)\n",
    "\n",
    "# test the score of the model\n",
    "predict_acc = model.score(X_test,Y_test)\n",
    "\n",
    "print((predict_acc-baseline_acc)/baseline_acc)\n",
    "\n",
    "#2\n",
    "# split the training and testing data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "a = [word[1] for word in Counter(Y_test).most_common(1)]\n",
    "baseline_acc = a[0]/len(Y_test)\n",
    "\n",
    "# fit the model to the training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# predict on the testing data\n",
    "model.predict(X_test)\n",
    "\n",
    "# test the score of the model\n",
    "predict_acc = model.score(X_test,Y_test)\n",
    "\n",
    "print((predict_acc-baseline_acc)/baseline_acc)\n",
    "\n",
    "#3\n",
    "# split the training and testing data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=3)\n",
    "a = [word[1] for word in Counter(Y_test).most_common(1)]\n",
    "baseline_acc = a[0]/len(Y_test)\n",
    "\n",
    "# fit the model to the training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# predict on the testing data\n",
    "model.predict(X_test)\n",
    "\n",
    "# test the score of the model\n",
    "predict_acc = model.score(X_test,Y_test)\n",
    "\n",
    "print((predict_acc-baseline_acc)/baseline_acc)\n",
    "\n",
    "#4\n",
    "# split the training and testing data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=15)\n",
    "a = [word[1] for word in Counter(Y_test).most_common(1)]\n",
    "baseline_acc = a[0]/len(Y_test)\n",
    "\n",
    "# fit the model to the training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# predict on the testing data\n",
    "model.predict(X_test)\n",
    "\n",
    "# test the score of the model\n",
    "predict_acc = model.score(X_test,Y_test)\n",
    "\n",
    "print((predict_acc-baseline_acc)/baseline_acc)\n",
    "\n",
    "#5\n",
    "# split the training and testing data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=4)\n",
    "a = [word[1] for word in Counter(Y_test).most_common(1)]\n",
    "baseline_acc = a[0]/len(Y_test)\n",
    "\n",
    "# fit the model to the training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# predict on the testing data\n",
    "model.predict(X_test)\n",
    "\n",
    "# test the score of the model\n",
    "predict_acc = model.score(X_test,Y_test)\n",
    "\n",
    "print((predict_acc-baseline_acc)/baseline_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17777777778\n",
      "2.0\n",
      "2.03846153846\n",
      "1.90566037736\n",
      "2.33333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from statistics import mode\n",
    "from collections import Counter\n",
    "\n",
    "hp = hp.dropna(axis=1)\n",
    "enc = LabelEncoder()\n",
    "for i in hp.columns:\n",
    "    hp[i] = enc.fit_transform(hp[i])\n",
    "\n",
    "\n",
    "# target is stored in y\n",
    "y = hp['Neighborhood']\n",
    "\n",
    "# X contains all other features, which we will use to predict target\n",
    "X = hp.drop('Neighborhood', axis=1)\n",
    "#1\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state =1)\n",
    "data = Counter(y_test)\n",
    "a = [word[1] for word in Counter(y_test).most_common(1)]\n",
    "baseline_acc = a[0]/len(y_test)\n",
    "\n",
    "# build model and fit on train set\n",
    "tree_classifier = DecisionTreeClassifier(max_leaf_nodes=15)\n",
    "tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# creates a file with the decision tree plotted\n",
    "with open(\"decisiontree.txt\", 'w') as f:\n",
    "    export_graphviz(tree_classifier, out_file=f, feature_names=list(X))\n",
    "    \n",
    "# make predictions on test set\n",
    "tree_pred = tree_classifier.predict(X_test)\n",
    "tree_pred\n",
    "\n",
    "# measure accuracy\n",
    "predict_acc = accuracy_score(y_true = y_test, y_pred = tree_pred)\n",
    "\n",
    "print((predict_acc-baseline_acc)/baseline_acc)\n",
    "\n",
    "#2\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state =2)\n",
    "a = [word[1] for word in Counter(y_test).most_common(1)]\n",
    "baseline_acc = a[0]/len(y_test)\n",
    "\n",
    "# build model and fit on train set\n",
    "tree_classifier = DecisionTreeClassifier(max_leaf_nodes=15)\n",
    "tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# creates a file with the decision tree plotted\n",
    "with open(\"decisiontree.txt\", 'w') as f:\n",
    "    export_graphviz(tree_classifier, out_file=f, feature_names=list(X))\n",
    "    \n",
    "# make predictions on test set\n",
    "tree_pred = tree_classifier.predict(X_test)\n",
    "tree_pred\n",
    "\n",
    "# measure accuracy\n",
    "predict_acc = accuracy_score(y_true = y_test, y_pred = tree_pred)\n",
    "\n",
    "print((predict_acc-baseline_acc)/baseline_acc)\n",
    "\n",
    "#3\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state =3)\n",
    "data = Counter(y_test)\n",
    "a = [word[1] for word in Counter(y_test).most_common(1)]\n",
    "baseline_acc = a[0]/len(y_test)\n",
    "\n",
    "# build model and fit on train set\n",
    "tree_classifier = DecisionTreeClassifier(max_leaf_nodes=15)\n",
    "tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# creates a file with the decision tree plotted\n",
    "with open(\"decisiontree.txt\", 'w') as f:\n",
    "    export_graphviz(tree_classifier, out_file=f, feature_names=list(X))\n",
    "    \n",
    "# make predictions on test set\n",
    "tree_pred = tree_classifier.predict(X_test)\n",
    "tree_pred\n",
    "\n",
    "# measure accuracy\n",
    "predict_acc = accuracy_score(y_true = y_test, y_pred = tree_pred)\n",
    "\n",
    "print((predict_acc-baseline_acc)/baseline_acc)\n",
    "\n",
    "#4\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state =4)\n",
    "data = Counter(y_test)\n",
    "a = [word[1] for word in Counter(y_test).most_common(1)]\n",
    "baseline_acc = a[0]/len(y_test)\n",
    "\n",
    "# build model and fit on train set\n",
    "tree_classifier = DecisionTreeClassifier(max_leaf_nodes=15)\n",
    "tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# creates a file with the decision tree plotted\n",
    "with open(\"decisiontree.txt\", 'w') as f:\n",
    "    export_graphviz(tree_classifier, out_file=f, feature_names=list(X))\n",
    "    \n",
    "# make predictions on test set\n",
    "tree_pred = tree_classifier.predict(X_test)\n",
    "tree_pred\n",
    "\n",
    "# measure accuracy\n",
    "predict_acc = accuracy_score(y_true = y_test, y_pred = tree_pred)\n",
    "\n",
    "print((predict_acc-baseline_acc)/baseline_acc)\n",
    "\n",
    "#5\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state =5)\n",
    "data = Counter(y_test)\n",
    "a = [word[1] for word in Counter(y_test).most_common(1)]\n",
    "baseline_acc = a[0]/len(y_test)\n",
    "\n",
    "# build model and fit on train set\n",
    "tree_classifier = DecisionTreeClassifier(max_leaf_nodes=15)\n",
    "tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# creates a file with the decision tree plotted\n",
    "with open(\"decisiontree.txt\", 'w') as f:\n",
    "    export_graphviz(tree_classifier, out_file=f, feature_names=list(X))\n",
    "    \n",
    "# make predictions on test set\n",
    "tree_pred = tree_classifier.predict(X_test)\n",
    "tree_pred\n",
    "\n",
    "# measure accuracy\n",
    "predict_acc = accuracy_score(y_true = y_test, y_pred = tree_pred)\n",
    "\n",
    "print((predict_acc-baseline_acc)/baseline_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
